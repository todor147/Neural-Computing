{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CS4287 Neural Computing - Assignment 2: Convolutional Neural Networks\n",
        "\n",
        "**Team Members:** [INSERT NAMES AND ID NUMBERS]  \n",
        "**Student ID 1:** [INSERT]  \n",
        "**Student ID 2:** [INSERT]\n",
        "\n",
        "**Code Execution Status:** [Comment on whether the code executes to completion without errors]\n",
        "\n",
        "**Third Party Source:** [Provide link to any existing implementation used]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Table of Contents\n",
        "1. [Imports and Setup](#imports)\n",
        "2. [Data Loading and Preprocessing](#data)\n",
        "3. [Network Architecture](#architecture)\n",
        "4. [Cost Function](#loss)\n",
        "5. [Optimizer](#optimizer)\n",
        "6. [Cross-Fold Validation](#validation)\n",
        "7. [Training and Results](#results)\n",
        "8. [Hyperparameter Analysis](#hyperparameters)\n",
        "9. [Evaluation](#evaluation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports and Setup {#imports}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Deep learning frameworks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, optimizers, losses, metrics\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Sklearn for evaluation and preprocessing\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {keras.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Loading and Preprocessing {#data}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Fruit Detection Dataset from Kaggle\n",
        "# Dataset: lakshaytyagi01/fruit-detection\n",
        "# Reorganized from YOLO format to classification format with 6 classes:\n",
        "# Apple, Banana, Grape, Orange, Pineapple, Watermelon\n",
        "\n",
        "DATASET_PATH = \"data/fruits_classification\"\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Load training dataset - Keras automatically creates labels from folder names\n",
        "train_dataset = keras.utils.image_dataset_from_directory(\n",
        "    f'{DATASET_PATH}/train',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Load test dataset\n",
        "test_dataset = keras.utils.image_dataset_from_directory(\n",
        "    f'{DATASET_PATH}/test',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Load validation dataset\n",
        "val_dataset = keras.utils.image_dataset_from_directory(\n",
        "    f'{DATASET_PATH}/valid',\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Get class names and number of classes\n",
        "class_names = train_dataset.class_names\n",
        "num_classes = len(class_names)\n",
        "\n",
        "print(f\"\\nDataset loaded successfully!\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Fruit classes: {class_names}\")\n",
        "print(f\"Number of training batches: {tf.data.experimental.cardinality(train_dataset).numpy()}\")\n",
        "print(f\"Number of test batches: {tf.data.experimental.cardinality(test_dataset).numpy()}\")\n",
        "print(f\"Number of validation batches: {tf.data.experimental.cardinality(val_dataset).numpy()}\")\n",
        "\n",
        "# Store image shape for later use\n",
        "input_shape = (*IMAGE_SIZE, 3)\n",
        "print(f\"Input shape: {input_shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Data Visualization\n",
        "\n",
        "Visualize sample fruit images and their distribution\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize sample fruits from training set\n",
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "# Get first batch from training data\n",
        "for images, labels in train_dataset.take(1):\n",
        "    # Display 16 sample images\n",
        "    for i in range(min(16, len(images))):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))  # Display image\n",
        "        # Get class name from one-hot encoded label\n",
        "        label_idx = np.argmax(labels[i].numpy())\n",
        "        plt.title(f\"{class_names[label_idx]}\", fontsize=10)\n",
        "        plt.axis('off')\n",
        "\n",
        "plt.suptitle('Sample Fruits from Training Set', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot class distribution\n",
        "class_counts = {}\n",
        "total_samples = 0\n",
        "\n",
        "# Count samples per class\n",
        "for images, labels in train_dataset:\n",
        "    for label in labels:\n",
        "        idx = np.argmax(label)\n",
        "        class_name = class_names[idx]\n",
        "        class_counts[class_name] = class_counts.get(class_name, 0) + len(images)\n",
        "    total_samples += len(images)\n",
        "\n",
        "# Visualize distribution\n",
        "plt.figure(figsize=(14, 6))\n",
        "bars = plt.bar(class_counts.keys(), class_counts.values(), color='steelblue', edgecolor='black')\n",
        "plt.title('Distribution of Fruit Classes in Training Set', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Fruit Class', fontsize=12)\n",
        "plt.ylabel('Number of Images', fontsize=12)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Add count labels on bars\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "            f'{int(height)}',\n",
        "            ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClass Distribution:\")\n",
        "for class_name, count in sorted(class_counts.items()):\n",
        "    percentage = (count / sum(class_counts.values())) * 100\n",
        "            print(f\"  {class_name}: {count} images ({percentage:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. CNN Architecture Definition {#architecture}\n",
        "\n",
        "Define the Convolutional Neural Network architecture for fruit detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build CNN Model for Fruit Detection\n",
        "def build_cnn_model(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Build a CNN model for fruit detection and classification.\n",
        "    \n",
        "    This architecture uses:\n",
        "    - He weight initialization (He et al., 2015) for ReLU activations\n",
        "    - Batch normalization (Ioffe & Szegedy, 2015) to stabilize training\n",
        "    - Max pooling for dimensionality reduction\n",
        "    - Dropout (Srivastava et al., 2014) for regularization\n",
        "    - Softmax activation for multi-class classification\n",
        "    \"\"\"\n",
        "    model = models.Sequential([\n",
        "        # First Convolutional Block - extracts basic visual features (edges, colors)\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape,\n",
        "                     kernel_initializer='he_normal', name='conv1_1'),  # He initialization\n",
        "        layers.BatchNormal要提高lization(name='bn1_1'),  # Batch norm for stability\n",
        "        layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                     kernel_initializer='he_normal', name='conv1_2'),\n",
        "        layers.BatchNormalization(name='bn1_2'),\n",
        "        layers.MaxPooling2D((2, 2), name='pool1'),  # Spatial dimension reduction\n",
        "        layers.Dropout(0.25, name='dropout1'),       # Regularization\n",
        "        \n",
        "        # Second Convolutional Block - extracts textures and patterns\n",
        "        layers.Conv2D(64, (3, 3), activation='relu',\n",
        "                     kernel_initializer='he_normal', name='conv2_1'),\n",
        "        layers.BatchNormalization(name='bn2_1'),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu',\n",
        "                     kernel_initializer='he_normal', name='conv2_2'),\n",
        "        layers.BatchNormalization(name='bn2_2'),\n",
        "        layers.MaxPooling2D((2, 2), name='pool2'),\n",
        "        layers.Dropout(0.25, name='dropout2'),\n",
        "        \n",
        "        # Third Convolutional Block - fruit-specific high-level features\n",
        "        layers.Conv2D(128, (3, 3), activation='relu',\n",
        "                     kernel_initializer='he_normal', name='conv3_1'),\n",
        "        layers.BatchNormalization(name='bn3_1'),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu',\n",
        "                     kernel_initializer='he_normal', name='conv3_2'),\n",
        "        layers.BatchNormalization(name='bn3_2'),\n",
        "        layers.MaxPooling2D((2, 2), name='pool3'),\n",
        "        layers.Dropout(0.25, name='dropout3'),\n",
        "        \n",
        "        # Fourth Convolutional Block - very high-level representations\n",
        "        layers.Conv2D(256, (3, 3), activation='relu',\n",
        "                     kernel_initializer='he_normal', name='conv4_1'),\n",
        "        layers.BatchNormalization(name='bn4_1'),\n",
        "        layers.Conv2D(256, (3, 3), activation='relu',\n",
        "                     kernel_initializer='he_normal', name='conv4_2'),\n",
        "        layers.BatchNormalization(name='bn4_2'),\n",
        "        layers.MaxPooling2D((2, 2), name='pool4'),\n",
        "        layers.Dropout(0.25, name='dropout4'),\n",
        "        \n",
        "        # Fully Connected Layers - classification\n",
        "        layers.Flatten(name='flatten'),              # Flatten for FC layers\n",
        "        layers.Dense(512, activation='relu',                # Hidden layer 1\n",
        "                    kernel_initializer='he_normal', name='fc1'),\n",
        "        layers.BatchNormalization(name='bn_fc1'),\n",
        "        layers.Dropout(0.5, name='dropout_fc1'),            # Higher dropout in FC\n",
        "        layers.Dense(256, activation='relu',                # Hidden layer 2\n",
        "                    kernel_initializer='he_normal', name='fc2'),\n",
        "        layers.BatchNormalization(name='bn_fc2'),\n",
        "        layers.Dropout(0.5, name='dropout_fc2'),\n",
        "        \n",
        "        # Output Layer - probability distribution over fruit classes\n",
        "        layers.Dense(num_classes, activation='softmax', name='output')  # Softmax for multi-class\n",
        "    ])\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "print(\"Building fruit detection CNN model...\")\n",
        "model = build_cnn_model(input_shape, num_classes)\n",
        "\n",
        "# Display model architecture\n",
        "model.summary()\n",
        "\n",
        "        print(f\"\\nModel built with {model.count_params():,} parameters\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
